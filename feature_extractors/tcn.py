from __future__ import annotations

from typing import Dict

import gymnasium as gym
import torch as th
import torch.nn as nn
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor

from .base import register

# @TODO: make feature extractors compatible with different observation builders

class _DilatedTCN(nn.Module):
    """
    Base TCN block

    Parameters:

    in_channels: Number of features per timestep fed to the first Conv1d layer

    n_filters: Number of convolutional filters in every layer

    n_blocks: How many BatchNorm (dilated Conv1d) blocks to stack

    kernel_size: Receptive field of each Conv1d (before dilation)
    """

    def __init__(
            self,
            in_channels: int,
            n_filters: int,
            n_blocks: int,
            kernel_size: int,
    ) -> None:
        super().__init__()
        layers = []
        dilation = 1
        for _ in range(n_blocks):
            layers += [
                nn.Conv1d(
                    in_channels=in_channels if dilation == 1 else n_filters,
                    out_channels=n_filters,
                    kernel_size=kernel_size,
                    padding=(kernel_size - 1) * dilation,
                    dilation=dilation,
                ),
                nn.GELU(),
                nn.BatchNorm1d(n_filters),
            ]
            dilation *= 2
        self.tcn = nn.Sequential(*layers)
        self.pool = nn.AdaptiveAvgPool1d(1)

    def forward(self, x: th.Tensor) -> th.Tensor:
        """
        Parameters:

        x : Tensor  (B, T, C)  where
        B = batch size,
        T = time-steps,
        C = in_channels.

        Returns:

        Tensor  (B, n_filters)
        """
        x = x.transpose(1, 2) # Conv1d expects (B, C, T)
        x = self.tcn(x) # (B, n_filters, T`)
        return self.pool(x).squeeze(-1) # (B, n_filters)



@register("tcn")
class TCNFeatureExtractor(BaseFeaturesExtractor):
    """
    Feature extractor that consumes the observation generated by
    MultiTimeframeObservationBuilder and converts it into a single dense
    feature vector of size features_dim.

    Each of the three sequence inputs (prices, 1-min indicators, 5-min
    indicators) gets its own DilatedTCN.

    Flat/categorical inputs (asset vector, private info, position matrix)
    are handled with small MLPs.
    """
    def __init__(
            self,
            observation_space: gym.spaces.Dict,
            *,
            n_filters: int = 64,
            n_blocks: int = 6,
            kernel_size: int = 3,
            pos_fc_dim: int = 32,
            priv_fc_dim: int = 8,
            asset_fc_dim: int = 4,
            features_dim: int = 128,
    ) -> None:
        super().__init__(observation_space, features_dim)

        win_p, n_price_feat = observation_space["prices"].shape
        win_1m, n_ind1_feat = observation_space["indicators_1m"].shape
        win_5m, n_ind5_feat = observation_space["indicators_5m"].shape
        n_assets = observation_space["asset"].shape[0]
        max_trades, pos_feat = observation_space["position_info"].shape

        assert win_p == win_1m

        self.price_tcn = _DilatedTCN(
            in_channels=n_price_feat,
            n_filters=n_filters,
            n_blocks=n_blocks,
            kernel_size=kernel_size,
        )
        self.ind1m_tcn = _DilatedTCN(n_ind1_feat, n_filters, n_blocks, kernel_size)
        self.ind5m_tcn = _DilatedTCN(n_ind5_feat, n_filters, n_blocks, kernel_size)

        self.asset_mlp = nn.Sequential(nn.Linear(n_assets, asset_fc_dim), nn.GELU())
        self.private_mlp = nn.Sequential(nn.Linear(2, priv_fc_dim), nn.GELU())
        self.position_mlp = nn.Sequential(
            nn.Flatten(),
            nn.Linear(max_trades * pos_feat, pos_fc_dim),
            nn.GELU(),
        )

        concat_dim = 3 * n_filters + asset_fc_dim + priv_fc_dim + pos_fc_dim
        self.fusion = nn.Sequential(nn.Linear(concat_dim, features_dim), nn.GELU())

    def forward(self, obs: Dict[str, th.Tensor]) -> th.Tensor:
        """
        Parameters
        ----------
        obs : Dict[str, Tensor]
            Observation as provided by the environment.

        Returns
        -------
        Tensor  (B, features_dim)
            Unified feature vector
        """
        price_feat = self.price_tcn(obs["prices"])
        ind1_feat = self.ind1m_tcn(obs["indicators_1m"])
        ind5_feat = self.ind5m_tcn(obs["indicators_5m"])
        asset_feat = self.asset_mlp(obs["asset"])
        priv_feat = self.private_mlp(obs["private_info"])
        pos_feat = self.position_mlp(obs["position_info"])

        fused = th.cat((price_feat, ind1_feat, ind5_feat, asset_feat, priv_feat, pos_feat), dim=-1)
        return self.fusion(fused)


__all__ = ["TCNFeatureExtractor"]
